{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "jupyter nbconvert --to notebook --execute Watersheds.ipynb --ExecutePreprocessor.timeout=-1 --ExectuePreprocessor.kernel_name=ILWA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks\n",
    "\n",
    "1. Climate Variable Visualization\n",
    "2. LOCA Bias Correction\n",
    "\n",
    "## Climate Variable Visualization\n",
    "\n",
    "We have the daily dataset which contains the aggregated ppt, tmin/max, and swe variables that are used in modeling.  \n",
    "The tasks is to create dynamic and interactive plots for a user to vizualize these climate variables.  \n",
    "We will likely want to have basic zoom and and variables selection capability.  \n",
    "Also, since these are aggregated to watersheds, we will also want to visualize the watersheds (maybe make an interactive paired map).\n",
    "This is pretty open ended, so have fun with it!\n",
    "\n",
    "## LOCA Bias Correction\n",
    "\n",
    "We have historical climate variables that are distributed in some way.  \n",
    "Out future climate scenarios are generated by the LOCA model, which is known to be biased.  \n",
    "The LOCA model overlaps the real data, allowing us to identify how much bias there is, and hopefully correct for it.\n",
    "The task is to visualize and qunatify the distributions of the real historical data, and then vis/quant the LOCA variables where they overlap.  \n",
    "Once we know how these variables are biased, we then need to figure out a way to correct for this bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio.features import geometry_mask\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.morphology import label\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from scipy.interpolate import griddata\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"/home/ScoutJarman/Code/ILWA/data/other/usgs_data.csv\", parse_dates=['datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp = df[['datetime', '309486_00062_00003']].dropna()\n",
    "# plt.plot(tmp['datetime'], tmp['309486_00062_00003'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(df['309486_00062_00003'].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shapefile_path = \"/home/ScoutJarman/Code/ILWA/data/shapefiles/id_ut8_1601.shp\"\n",
    "\n",
    "# watersheds = gpd.read_file(shapefile_path)\n",
    "# watersheds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raster_path = \"/home/ScoutJarman/Code/ILWA/data/rasters/UA/swe_81-23/swe19811028.tif\"\n",
    "\n",
    "# with rasterio.open(raster_path) as handle:\n",
    "#     raster_arr = handle.read(1)\n",
    "#     meta = handle.meta\n",
    "\n",
    "# plt.imshow(raster_arr)\n",
    "# meta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seg = np.zeros_like(raster_arr)\n",
    "# for idx, geometry in enumerate(watersheds['geometry']):\n",
    "#     mask = geometry_mask([geometry], out_shape=raster_arr.shape, transform=meta['transform'], invert=True)\n",
    "#     seg[mask] = idx + 1\n",
    "\n",
    "# seg = label(seg, background=-1) - 1\n",
    "# plt.imshow(seg, cmap='Set1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agg_img = np.zeros_like(raster_arr)\n",
    "# means = []\n",
    "# for l in np.unique(seg):\n",
    "#     m = raster_arr[seg == l].mean()\n",
    "#     means.append(m)\n",
    "#     agg_img[seg == l] = m\n",
    "\n",
    "\n",
    "# fig, axs = plt.subplots(1, 3)\n",
    "# fig.set_size_inches(15, 5)\n",
    "\n",
    "# axs[1].imshow(agg_img, cmap='hot', vmin=raster_arr.min(), vmax=raster_arr.max())\n",
    "# axs[1].set_title(\"Averaged by Watershed\")\n",
    "# img = axs[0].imshow(raster_arr, cmap='hot')\n",
    "# axs[0].set_title(\"Precip\")\n",
    "# plt.colorbar(img, ax=axs[0])\n",
    "# axs[2].plot(means)\n",
    "# axs[2].set_xlabel(\"Segment Label\")\n",
    "# axs[2].set_ylabel(\"Average Precip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in SWE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read layer names from the JSON file\n",
    "# with open(\"/home/ScoutJarman/Code/ILWA/data/rasters/UA/ua_swe_daily_bearlake.tif.aux.json\", 'r') as json_file:\n",
    "#     layer_names = json.load(json_file)['time']\n",
    "\n",
    "# input_path = \"/home/ScoutJarman/Code/ILWA/data/rasters/UA/ua_swe_daily_bearlake.tif\"\n",
    "# output_directory = \"/home/ScoutJarman/Code/ILWA/data/rasters/UA/swe_81-23/\"\n",
    "\n",
    "# if not os.path.exists(output_directory):\n",
    "#     os.makedirs(output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Open the original raster file\n",
    "# with rasterio.open(input_path) as src:\n",
    "#     # Loop through bands and layer names\n",
    "#     for band_idx, layer_name in tqdm(zip(range(1, src.count + 1), layer_names), total=src.count):\n",
    "#         # Read the band data\n",
    "#         band_data = src.read(band_idx)\n",
    "\n",
    "#         # Do nearest neighbor interpolation for lake values\n",
    "#         non_nan_indices = np.where(~np.isnan(band_data))\n",
    "#         points = np.column_stack((non_nan_indices[1], non_nan_indices[0]))\n",
    "#         values = band_data[non_nan_indices]\n",
    "#         rows, cols = band_data.shape\n",
    "#         grid_x, grid_y = np.meshgrid(np.arange(cols), np.arange(rows))\n",
    "#         interpolated_values = griddata(points, values, (grid_x, grid_y), method='nearest')\n",
    "#         band_data[np.isnan(band_data)] = interpolated_values[np.isnan(band_data)]\n",
    "\n",
    "#         year, month, day = layer_name.split(\"-\")\n",
    "#         # Create a new raster file for each band with the corresponding layer name\n",
    "#         output_raster_path = f\"{output_directory}/swe{int(year)}{int(month):02d}{int(day):02d}.tif\"\n",
    "\n",
    "#         # Write the band data to the new raster file with the same metadata\n",
    "#         with rasterio.open(output_raster_path, 'w', **src.profile) as dst:\n",
    "#             dst.write(band_data, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format LOCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read layer names from the JSON file\n",
    "for in_var, out_var in zip([\"pr\", \"tasmax\", \"tasmin\"], ['ppt', 'tmax', 'tmin']):\n",
    "    output_directories = [f\"/home/ScoutJarman/Code/ILWA/data/rasters/LOCA/{out_var}_{i}/\" for i in [\"r1\", \"r2\", \"r3\"]]\n",
    "    \n",
    "    r1_tiffs = [\n",
    "        f\"/home/ScoutJarman/Code/ILWA/data/rasters/bear_lake/{in_var}/historical/day/bearlake_pr.ACCESS-CM2.historical.r1i1p1f1.1950-2014.LOCA_16thdeg_v20220519.tif\",\n",
    "        f\"/home/ScoutJarman/Code/ILWA/data/rasters/bear_lake/{in_var}/future/day/bearlake_pr.ACCESS-CM2.ssp585.r1i1p1f1.2015-2044.LOCA_16thdeg_v20220519.tif\",\n",
    "        f\"/home/ScoutJarman/Code/ILWA/data/rasters/bear_lake/{in_var}/future/day/bearlake_pr.ACCESS-CM2.ssp585.r1i1p1f1.2045-2074.LOCA_16thdeg_v20220519.tif\",\n",
    "        f\"/home/ScoutJarman/Code/ILWA/data/rasters/bear_lake/{in_var}/future/day/bearlake_pr.ACCESS-CM2.ssp585.r1i1p1f1.2075-2100.LOCA_16thdeg_v20220519.tif\"\n",
    "    ]\n",
    "    r2_tiffs = [\n",
    "        f\"/home/ScoutJarman/Code/ILWA/data/rasters/bear_lake/{in_var}/historical/day/bearlake_pr.ACCESS-CM2.historical.r2i1p1f1.1950-2014.LOCA_16thdeg_v20220519.tif\",\n",
    "        f\"/home/ScoutJarman/Code/ILWA/data/rasters/bear_lake/{in_var}/future/day/bearlake_pr.ACCESS-CM2.ssp585.r2i1p1f1.2015-2044.LOCA_16thdeg_v20220519.tif\",\n",
    "        f\"/home/ScoutJarman/Code/ILWA/data/rasters/bear_lake/{in_var}/future/day/bearlake_pr.ACCESS-CM2.ssp585.r2i1p1f1.2045-2074.LOCA_16thdeg_v20220519.tif\",\n",
    "        f\"/home/ScoutJarman/Code/ILWA/data/rasters/bear_lake/{in_var}/future/day/bearlake_pr.ACCESS-CM2.ssp585.r2i1p1f1.2075-2100.LOCA_16thdeg_v20220519.tif\"\n",
    "    ]\n",
    "    r3_tiffs = [\n",
    "        f\"/home/ScoutJarman/Code/ILWA/data/rasters/bear_lake/{in_var}/historical/day/bearlake_pr.ACCESS-CM2.historical.r3i1p1f1.1950-2014.LOCA_16thdeg_v20220519.tif\",\n",
    "        f\"/home/ScoutJarman/Code/ILWA/data/rasters/bear_lake/{in_var}/future/day/bearlake_pr.ACCESS-CM2.ssp585.r3i1p1f1.2015-2044.LOCA_16thdeg_v20220519.tif\",\n",
    "        f\"/home/ScoutJarman/Code/ILWA/data/rasters/bear_lake/{in_var}/future/day/bearlake_pr.ACCESS-CM2.ssp585.r3i1p1f1.2045-2074.LOCA_16thdeg_v20220519.tif\",\n",
    "        f\"/home/ScoutJarman/Code/ILWA/data/rasters/bear_lake/{in_var}/future/day/bearlake_pr.ACCESS-CM2.ssp585.r3i1p1f1.2075-2100.LOCA_16thdeg_v20220519.tif\"\n",
    "    ]\n",
    "\n",
    "    for i, tiffs in enumerate([r1_tiffs, r2_tiffs, r3_tiffs]):\n",
    "        # Check and make outputdirectory for r level\n",
    "        output_directory = output_directories[i]\n",
    "        if not os.path.exists(output_directory):\n",
    "            print(f\"Making {output_directory}\")\n",
    "            os.makedirs(output_directory)\n",
    "        # Loop through each of the different tiff files\n",
    "        for input_path in tiffs:\n",
    "            with open(input_path + \".aux.json\", 'r') as json_handle:\n",
    "                layer_names = json.load(json_handle)['time']\n",
    "            # Open tiff and write each layer to new file\n",
    "            with rasterio.open(input_path) as src:\n",
    "                # Loop through bands and layer names\n",
    "                for band_idx, layer_name in tqdm(zip(range(1, src.count + 1), layer_names), total=src.count):\n",
    "                    # Read the band data\n",
    "                    band_data = src.read(band_idx)\n",
    "\n",
    "                    # Do nearest neighbor interpolation for lake values\n",
    "                    non_nan_indices = np.where(~np.isnan(band_data))\n",
    "                    points = np.column_stack((non_nan_indices[1], non_nan_indices[0]))\n",
    "                    values = band_data[non_nan_indices]\n",
    "                    rows, cols = band_data.shape\n",
    "                    grid_x, grid_y = np.meshgrid(np.arange(cols), np.arange(rows))\n",
    "                    interpolated_values = griddata(points, values, (grid_x, grid_y), method='nearest')\n",
    "                    band_data[np.isnan(band_data)] = interpolated_values[np.isnan(band_data)]\n",
    "\n",
    "                    year, month, day = layer_name.split(\"-\")\n",
    "                    # Create a new raster file for each band with the corresponding layer name\n",
    "                    output_raster_path = f\"{output_directory}/{out_var}{int(year)}{int(month):02d}{int(day):02d}.tif\"\n",
    "\n",
    "                    # Write the band data to the new raster file with the same metadata\n",
    "                    with rasterio.open(output_raster_path, 'w', **src.profile) as dst:\n",
    "                        dst.write(band_data, 1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_tif_files(directory, var_n):\n",
    "    pt_tif_files = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if var_n in filename and filename.endswith(\".tif\"):\n",
    "            pt_tif_files.append(os.path.join(directory, filename))\n",
    "    return pt_tif_files\n",
    "\n",
    "for v in [\"pr\", \"tasmax\", \"tasmin\"]:\n",
    "    all_files += get_tif_files(\"/data/ScoutJarman/LOCA/NCAR/met/ACCESS1-0/historical/\", v)\n",
    "all_files += get_tif_files(\"/data/ScoutJarman/LOCA/NCAR/vic/ACCESS1-0/historical/\", \"SWE\")\n",
    "\n",
    "for v in [\"pr\", \"tasmax\", \"tasmin\"]:\n",
    "    all_files += get_tif_files(f\"/data/ScoutJarman/LOCA/NCAR/met/ACCESS1-0/{scenario}/\", v)\n",
    "all_files += get_tif_files(f\"/data/ScoutJarman/LOCA/NCAR/vic/ACCESS1-0/{scenario}/\", \"SWE\")\n",
    "# all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read layer names from the JSON file\n",
    "for in_var, out_var in zip([\"pr\", \"tasmax\", \"tasmin\", \"SWE\"], ['ppt', 'tmax', 'tmin', 'swe']):\n",
    "    output_directories = [f\"/data/ScoutJarman/LOCA/LOCA/{out_var}_{i}/\" for i in [\"rcp45\", \"rcp85\"]]\n",
    "    for directory in output_directories:\n",
    "        if not os.path.exists(directory):\n",
    "            print(f\"Making {directory}\")\n",
    "            os.makedirs(directory)\n",
    "    \n",
    "    if in_var != \"SWE\":\n",
    "        tiffs_45 = get_tif_files(\"/data/ScoutJarman/LOCA/NCAR/met/ACCESS1-0/historical/\", in_var)\n",
    "        tiffs_45 += get_tif_files(f\"/data/ScoutJarman/LOCA/NCAR/met/ACCESS1-0/rcp45/\", in_var)\n",
    "        tiffs_85 = get_tif_files(\"/data/ScoutJarman/LOCA/NCAR/met/ACCESS1-0/historical/\", in_var)\n",
    "        tiffs_85 += get_tif_files(f\"/data/ScoutJarman/LOCA/NCAR/met/ACCESS1-0/rcp85/\", in_var)\n",
    "    else:\n",
    "        tiffs_45 = get_tif_files(\"/data/ScoutJarman/LOCA/NCAR/vic/ACCESS1-0/historical/\", in_var)\n",
    "        tiffs_45 += get_tif_files(f\"/data/ScoutJarman/LOCA/NCAR/vic/ACCESS1-0/rcp45/\", in_var)\n",
    "        tiffs_85 = get_tif_files(\"/data/ScoutJarman/LOCA/NCAR/vic/ACCESS1-0/historical/\", in_var)\n",
    "        tiffs_85 += get_tif_files(f\"/data/ScoutJarman/LOCA/NCAR/vic/ACCESS1-0/rcp85/\", in_var)\n",
    "\n",
    "    for i, tiffs in enumerate([tiffs_45, tiffs_85]):\n",
    "        output_directory = output_directories[i]\n",
    "        # Loop through each of the different tiff files\n",
    "        for input_path in tiffs:\n",
    "            with open(input_path + \".aux.json\", 'r') as json_handle:\n",
    "                layer_names = json.load(json_handle)['time']\n",
    "            # Open tiff and write each layer to new file\n",
    "            with rasterio.open(input_path) as src:\n",
    "                # Loop through bands and layer names\n",
    "                for band_idx, layer_name in tqdm(zip(range(1, src.count + 1), layer_names), total=src.count):\n",
    "                    # Read the band data\n",
    "                    band_data = src.read(band_idx)\n",
    "\n",
    "                    # Do nearest neighbor interpolation for lake values\n",
    "                    non_nan_indices = np.where(~np.isnan(band_data))\n",
    "                    points = np.column_stack((non_nan_indices[1], non_nan_indices[0]))\n",
    "                    values = band_data[non_nan_indices]\n",
    "                    rows, cols = band_data.shape\n",
    "                    grid_x, grid_y = np.meshgrid(np.arange(cols), np.arange(rows))\n",
    "                    interpolated_values = griddata(points, values, (grid_x, grid_y), method='nearest')\n",
    "                    band_data[np.isnan(band_data)] = interpolated_values[np.isnan(band_data)]\n",
    "\n",
    "                    year, month, day = layer_name.split(\"-\")\n",
    "                    # Create a new raster file for each band with the corresponding layer name\n",
    "                    output_raster_path = f\"{output_directory}/{out_var}{int(year)}{int(month):02d}{int(day):02d}.tif\"\n",
    "\n",
    "                    # Write the band data to the new raster file with the same metadata\n",
    "                    with rasterio.open(output_raster_path, 'w', **src.profile) as dst:\n",
    "                        dst.write(band_data, 1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def generate_days(year):\n",
    "    start_date = datetime.date(year, 1, 1)\n",
    "    end_date = datetime.date(year, 12, 31)\n",
    "    delta = datetime.timedelta(days=1)\n",
    "\n",
    "    days_in_year = []\n",
    "    current_date = start_date\n",
    "    while current_date <= end_date:\n",
    "        days_in_year.append(current_date.strftime(\"%Y-%m-%d\"))\n",
    "        current_date += delta\n",
    "\n",
    "    return days_in_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1950', '01', '01']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_days(1950)[0].split(\"-\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ILWA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
